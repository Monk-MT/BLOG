# 软解流程分析

## video_thread 调用流程

```java
// ff_ffpipenode.h
typedef struct IJKFF_Pipenode IJKFF_Pipenode;
struct IJKFF_Pipenode {
    SDL_mutex *mutex;
    void *opaque;

    void (*func_destroy) (IJKFF_Pipenode *node);
    int  (*func_run_sync)(IJKFF_Pipenode *node);
    int  (*func_flush)   (IJKFF_Pipenode *node); // optional
};

// ff_ffplay.c
static int stream_component_open(FFPlayer *ffp, int stream_index) {
    decoder_init(&is->viddec, avctx, &is->videoq, is->continue_read_thread);
    // 创建 IJKFF_Pipenode，创建并初始化解码器，ffpipenode 封装了硬/软解码器
    ffp->node_vdec = ffpipeline_open_video_decoder(ffp->pipeline, ffp);
    // 开启解码线程
    decoder_start(&is->viddec, video_thread, ffp, "ff_video_dec");
}

// ff_ffpipeline.c
IJKFF_Pipenode* ffpipeline_open_video_decoder(IJKFF_Pipeline *pipeline, FFPlayer *ffp)
{
    live_log(ffp->inject_opaque, NULL);
    return pipeline->func_open_video_decoder(pipeline, ffp);
}

// ffpipeline_android.c
// 这里有一个指针 pipeline->func_open_video_decoder = func_open_video_decoder;
static IJKFF_Pipenode *func_open_video_decoder(IJKFF_Pipeline *pipeline, FFPlayer *ffp)
{
    IJKFF_Pipeline_Opaque *opaque = pipeline->opaque;
    IJKFF_Pipenode        *node = NULL;

    if (ffp->mediacodec_all_videos || ffp->mediacodec_avc || ffp->mediacodec_hevc || ffp->mediacodec_mpeg2)
        // 硬解
        node = ffpipenode_create_video_decoder_from_android_mediacodec(ffp, pipeline, opaque->weak_vout);

    if (!node) {
        // 硬解创建失败走软解
        node = ffpipenode_create_video_decoder_from_ffplay(ffp);
    }

    return node;
}

// ff_ffplay.c
static int decoder_start(Decoder *d, int (*fn)(void *), void *arg, const char *name) {
    packet_queue_start(d->queue);
    //解码流程由传入参数 fn 决定，此时为 video_thread
    d->decoder_tid = SDL_CreateThreadEx(&d->_decoder_tid, fn, arg, name); 
}

// ff_ffplay.c
static int video_thread(void *arg) {
    ret = ffpipenode_run_sync(ffp->node_vdec);
    return ret;
}

// ff_ffpipenode.c
int ffpipenode_run_sync(IJKFF_Pipenode *node) {
    return node->func_run_sync(node);
}

```

## 视频帧解码流程的选择

在 video_thread 中调用 ffpipenode_run_sync 就区分开了，视频解码分为软解和硬解；
软解的实现是在 ffpipenode_ffplay_vdec.c，
硬解的实现是在 ffpipenode_android_mediacodec_vdec.c，

软件流程会调到`ff_ffplay.c # ffp_video_thread`中；
硬件流程就在`ffpipenode_android_mediacodec_vdec.c`文件中

软解具体的调用过程如下

```java
// ffpipenode_ffplay_vdec.c
IJKFF_Pipenode *ffpipenode_create_video_decoder_from_ffplay(FFPlayer *ffp) {
    node->func_run_sync = func_run_sync;
}

// ffpipenode_ffplay_vdec.c
static int func_run_sync(IJKFF_Pipenode *node){
    IJKFF_Pipenode_Opaque *opaque = node->opaque;
    return ffp_video_thread(opaque->ffp);
}

// ff_ffplay.c
int ffp_video_thread(FFPlayer *ffp){
    return ffplay_video_thread(ffp);
}

```

## 软解流程

```java
// ijkmedia\ijkplayer\ff_ffplay.c
static int ffplay_video_thread(void *arg) {
    for (;;) {
        //解码获取一帧视频画面
        ret = get_video_frame(ffp, frame); 
    }
}

// ijkmedia\ijkplayer\ff_ffplay.c
static int get_video_frame(FFPlayer *ffp, AVFrame *frame) {
    //获取解码帧数据（音频、视频、字幕都调用这个函数）
    got_picture = decoder_decode_frame(ffp, &is->viddec, frame, NULL); 
}

// ijkmedia\ijkplayer\ff_ffplay.c
static int decoder_decode_frame(FFPlayer *ffp, Decoder *d, AVFrame *frame, AVSubtitle *sub) {
    for (;;) {
        //获取解码后的 Frame
        ret = avcodec_receive_frame(d->avctx, frame);
    }
}

//后面的解码函数都不在 ijkplayer 中，而在在 FFmpeg 中了
// FFmpeg-ff3.4-ijk0.8.7-20180103-001\libavcodec\decode.c
static int decode_receive_frame_internal(AVCodecContext *avctx, AVFrame *frame) {
        ret = decode_simple_receive_frame(avctx, frame);
}

// FFmpeg-ff3.4-ijk0.8.7-20180103-001\libavcodec\decode.c
static int decode_simple_receive_frame(AVCodecContext *avctx, AVFrame *frame) {
    ret = decode_simple_internal(avctx, frame);
}

//
static int decode_simple_internal(AVCodecContext *avctx, AVFrame *frame) {
    ret = ff_decode_get_packet(avctx, pkt);
}

```
